{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With rgb images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_filename = \"D:/Minor/minor chester/train_data_sample_rgb.p\"\n",
    "(train_labels, train_data, train_tensors) = pickle.load(open(train_filename, mode='rb'))\n",
    "\n",
    "valid_filename = \"D:/Minor/minor chester/valid_data_sample_rgb.p\"\n",
    "(valid_labels, valid_data, valid_tensors) = pickle.load(open(valid_filename, mode='rb'))\n",
    "\n",
    "test_filename = \"'D:/Minor/minor chester/test_data_sample_rgb.p\"\n",
    "(test_labels, test_data, test_tensors) = pickle.load(open(test_filename, mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\u001b[0m in \u001b[0;36mfind_module\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ERR_MSG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# use `dlopen()` for dynamic loading.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b60828828ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 72\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 322,793\n",
      "Trainable params: 322,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers, initializers, optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=7,padding='same',activation='relu', \n",
    "                 input_shape=train_tensors.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=5,\n",
    "                 strides=2,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\u001b[0m in \u001b[0;36mfind_module\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ERR_MSG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# use `dlopen()` for dynamic loading.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e6cd7dde1db1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m model.compile(optimizer='sgd', loss='binary_crossentropy', \n\u001b[0;32m      5\u001b[0m               metrics=[precision_threshold(threshold = 0.5), \n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 72\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"c:\\users\\arpit\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', \n",
    "              metrics=[precision_threshold(threshold = 0.5), \n",
    "                       recall_threshold(threshold = 0.5), \n",
    "                       fbeta_score_threshold(beta=0.5, threshold = 0.5),\n",
    "                      'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3400 samples, validate on 1100 samples\n",
      "Epoch 1/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6840 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5486\n",
      "Epoch 00001: val_loss improved from inf to 0.68587, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 776us/sample - loss: 0.6840 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5485 - val_loss: 0.6859 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5345\n",
      "Epoch 2/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6828 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5478\n",
      "Epoch 00002: val_loss improved from 0.68587 to 0.68453, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 770us/sample - loss: 0.6827 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5482 - val_loss: 0.6845 - val_precision: 0.0571 - val_recall: 0.0042 - val_fbeta_score: 0.0161 - val_acc: 0.5364\n",
      "Epoch 3/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6799 - precision: 0.0757 - recall: 0.0197 - fbeta_score: 0.0429 - acc: 0.5532\n",
      "Epoch 00003: val_loss improved from 0.68453 to 0.68387, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 724us/sample - loss: 0.6801 - precision: 0.0829 - recall: 0.0199 - fbeta_score: 0.0446 - acc: 0.5529 - val_loss: 0.6839 - val_precision: 0.6778 - val_recall: 0.3038 - val_fbeta_score: 0.5305 - val_acc: 0.6027\n",
      "Epoch 4/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6777 - precision: 0.3697 - recall: 0.0790 - fbeta_score: 0.1862 - acc: 0.5660\n",
      "Epoch 00004: val_loss improved from 0.68387 to 0.67815, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 791us/sample - loss: 0.6776 - precision: 0.3662 - recall: 0.0783 - fbeta_score: 0.1845 - acc: 0.5659 - val_loss: 0.6782 - val_precision: 0.3881 - val_recall: 0.0481 - val_fbeta_score: 0.1512 - val_acc: 0.5455\n",
      "Epoch 5/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6731 - precision: 0.5006 - recall: 0.1978 - fbeta_score: 0.3333 - acc: 0.5828\n",
      "Epoch 00005: val_loss improved from 0.67815 to 0.67676, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 713us/sample - loss: 0.6731 - precision: 0.5053 - recall: 0.1978 - fbeta_score: 0.3353 - acc: 0.5826 - val_loss: 0.6768 - val_precision: 0.5793 - val_recall: 0.6281 - val_fbeta_score: 0.5823 - val_acc: 0.6145\n",
      "Epoch 6/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6694 - precision: 0.6053 - recall: 0.3295 - fbeta_score: 0.4647 - acc: 0.5916\n",
      "Epoch 00006: val_loss improved from 0.67676 to 0.67212, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 769us/sample - loss: 0.6690 - precision: 0.6018 - recall: 0.3246 - fbeta_score: 0.4596 - acc: 0.5912 - val_loss: 0.6721 - val_precision: 0.5791 - val_recall: 0.6242 - val_fbeta_score: 0.5820 - val_acc: 0.6118\n",
      "Epoch 7/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6650 - precision: 0.6149 - recall: 0.3894 - fbeta_score: 0.5082 - acc: 0.6034\n",
      "Epoch 00007: val_loss did not improve from 0.67212\n",
      "3400/3400 [==============================] - 3s 773us/sample - loss: 0.6636 - precision: 0.6234 - recall: 0.3856 - fbeta_score: 0.5103 - acc: 0.6053 - val_loss: 0.6775 - val_precision: 0.6660 - val_recall: 0.1698 - val_fbeta_score: 0.3975 - val_acc: 0.5736\n",
      "Epoch 8/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6626 - precision: 0.6079 - recall: 0.3978 - fbeta_score: 0.5074 - acc: 0.5988\n",
      "Epoch 00008: val_loss did not improve from 0.67212\n",
      "3400/3400 [==============================] - 2s 690us/sample - loss: 0.6621 - precision: 0.6115 - recall: 0.4035 - fbeta_score: 0.5120 - acc: 0.5997 - val_loss: 0.7483 - val_precision: 0.4000 - val_recall: 0.0371 - val_fbeta_score: 0.1278 - val_acc: 0.5464\n",
      "Epoch 9/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6622 - precision: 0.6015 - recall: 0.4119 - fbeta_score: 0.5197 - acc: 0.6067\n",
      "Epoch 00009: val_loss improved from 0.67212 to 0.66656, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 736us/sample - loss: 0.6622 - precision: 0.5976 - recall: 0.4077 - fbeta_score: 0.5161 - acc: 0.6065 - val_loss: 0.6666 - val_precision: 0.6850 - val_recall: 0.3030 - val_fbeta_score: 0.5277 - val_acc: 0.6000\n",
      "Epoch 10/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6544 - precision: 0.6056 - recall: 0.4115 - fbeta_score: 0.5278 - acc: 0.6129 ETA: 1s - loss: 0.6636 - precision: 0.6\n",
      "Epoch 00010: val_loss did not improve from 0.66656\n",
      "3400/3400 [==============================] - 2s 723us/sample - loss: 0.6542 - precision: 0.6070 - recall: 0.4170 - fbeta_score: 0.5302 - acc: 0.6135 - val_loss: 0.6686 - val_precision: 0.6260 - val_recall: 0.3054 - val_fbeta_score: 0.5050 - val_acc: 0.5918\n",
      "Epoch 11/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6550 - precision: 0.6182 - recall: 0.4343 - fbeta_score: 0.5442 - acc: 0.6141\n",
      "Epoch 00011: val_loss improved from 0.66656 to 0.66338, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 726us/sample - loss: 0.6549 - precision: 0.6180 - recall: 0.4395 - fbeta_score: 0.5453 - acc: 0.6144 - val_loss: 0.6634 - val_precision: 0.6350 - val_recall: 0.3490 - val_fbeta_score: 0.5302 - val_acc: 0.6055\n",
      "Epoch 12/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6558 - precision: 0.6055 - recall: 0.4410 - fbeta_score: 0.5304 - acc: 0.6148\n",
      "Epoch 00012: val_loss improved from 0.66338 to 0.65787, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 766us/sample - loss: 0.6557 - precision: 0.6069 - recall: 0.4468 - fbeta_score: 0.5337 - acc: 0.6159 - val_loss: 0.6579 - val_precision: 0.5978 - val_recall: 0.5257 - val_fbeta_score: 0.5743 - val_acc: 0.6118\n",
      "Epoch 13/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6563 - precision: 0.6169 - recall: 0.4578 - fbeta_score: 0.5568 - acc: 0.6185\n",
      "Epoch 00013: val_loss improved from 0.65787 to 0.65739, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 757us/sample - loss: 0.6557 - precision: 0.6210 - recall: 0.4591 - fbeta_score: 0.5602 - acc: 0.6197 - val_loss: 0.6574 - val_precision: 0.5780 - val_recall: 0.4944 - val_fbeta_score: 0.5526 - val_acc: 0.6155\n",
      "Epoch 14/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6531 - precision: 0.6285 - recall: 0.4651 - fbeta_score: 0.5711 - acc: 0.6280\n",
      "Epoch 00014: val_loss did not improve from 0.65739\n",
      "3400/3400 [==============================] - 2s 723us/sample - loss: 0.6529 - precision: 0.6302 - recall: 0.4698 - fbeta_score: 0.5741 - acc: 0.6282 - val_loss: 0.6577 - val_precision: 0.5958 - val_recall: 0.5925 - val_fbeta_score: 0.5896 - val_acc: 0.6227\n",
      "Epoch 15/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6541 - precision: 0.6131 - recall: 0.4761 - fbeta_score: 0.5596 - acc: 0.6182 ETA: 1s - loss: 0.6531 - precision:\n",
      "Epoch 00015: val_loss did not improve from 0.65739\n",
      "3400/3400 [==============================] - 2s 712us/sample - loss: 0.6541 - precision: 0.6121 - recall: 0.4748 - fbeta_score: 0.5586 - acc: 0.6182 - val_loss: 0.6646 - val_precision: 0.6924 - val_recall: 0.3010 - val_fbeta_score: 0.5289 - val_acc: 0.6036\n",
      "Epoch 16/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6521 - precision: 0.6122 - recall: 0.4564 - fbeta_score: 0.5565 - acc: 0.6215\n",
      "Epoch 00016: val_loss improved from 0.65739 to 0.65567, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 760us/sample - loss: 0.6524 - precision: 0.6065 - recall: 0.4521 - fbeta_score: 0.5513 - acc: 0.6212 - val_loss: 0.6557 - val_precision: 0.6053 - val_recall: 0.5203 - val_fbeta_score: 0.5790 - val_acc: 0.6164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6507 - precision: 0.6321 - recall: 0.4735 - fbeta_score: 0.5766 - acc: 0.6315\n",
      "Epoch 00017: val_loss did not improve from 0.65567\n",
      "3400/3400 [==============================] - 3s 781us/sample - loss: 0.6506 - precision: 0.6293 - recall: 0.4784 - fbeta_score: 0.5748 - acc: 0.6318 - val_loss: 0.6894 - val_precision: 0.6871 - val_recall: 0.1963 - val_fbeta_score: 0.4297 - val_acc: 0.5827\n",
      "Epoch 18/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6481 - precision: 0.6332 - recall: 0.4561 - fbeta_score: 0.5669 - acc: 0.6262 ETA: 1s - loss: 0.6461 - precision: 0.6353 - recall: 0.4371\n",
      "Epoch 00018: val_loss improved from 0.65567 to 0.65291, saving model to C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 837us/sample - loss: 0.6475 - precision: 0.6326 - recall: 0.4597 - fbeta_score: 0.5675 - acc: 0.6268 - val_loss: 0.6529 - val_precision: 0.6272 - val_recall: 0.4852 - val_fbeta_score: 0.5829 - val_acc: 0.6227\n",
      "Epoch 19/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6493 - precision: 0.6201 - recall: 0.4843 - fbeta_score: 0.5744 - acc: 0.6319\n",
      "Epoch 00019: val_loss did not improve from 0.65291\n",
      "3400/3400 [==============================] - 3s 761us/sample - loss: 0.6488 - precision: 0.6181 - recall: 0.4869 - fbeta_score: 0.5733 - acc: 0.6324 - val_loss: 0.6840 - val_precision: 0.6637 - val_recall: 0.2339 - val_fbeta_score: 0.4731 - val_acc: 0.5936\n",
      "Epoch 20/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6470 - precision: 0.6471 - recall: 0.4758 - fbeta_score: 0.5839 - acc: 0.6362 ETA: 1s - loss: 0.6463 - precision: 0.6387 - reca\n",
      "Epoch 00020: val_loss did not improve from 0.65291\n",
      "3400/3400 [==============================] - 2s 712us/sample - loss: 0.6468 - precision: 0.6480 - recall: 0.4784 - fbeta_score: 0.5854 - acc: 0.6365 - val_loss: 0.6530 - val_precision: 0.6242 - val_recall: 0.4868 - val_fbeta_score: 0.5779 - val_acc: 0.6182\n",
      "training time: 0.86 minutes\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "log = CSVLogger('C:/Users/behl/Desktop/minor/log_bCNN_rgb.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='C:/Users/behl/Desktop/minor/bCNN.best.from_scratch.hdf5', \n",
    "                               monitor = 'val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, valid_labels),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# Show total training time\n",
    "print(\"training time: %.2f minutes\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3418ff1ee493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Minor/minor chester/bCNN.best.from_scratch.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights('D:/Minor/minor chester/bCNN.best.from_scratch.hdf5')\n",
    "prediction = model.predict(test_tensors)\n",
    "print('prediction',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-58ff06de31c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n\u001b[0m\u001b[0;32m      5\u001b[0m                                    K.variable(value=prediction)))\n\u001b[0;32m      6\u001b[0m rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2dbb395ebae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m K.eval(binary_accuracy(K.variable(value=test_labels),\n\u001b[0m\u001b[0;32m      2\u001b[0m                                    K.variable(value=prediction)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "K.eval(binary_accuracy(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4363243 ],\n",
       "       [0.34560972],\n",
       "       [0.6282389 ],\n",
       "       [0.3624897 ],\n",
       "       [0.44472387],\n",
       "       [0.4790499 ],\n",
       "       [0.60046285],\n",
       "       [0.28872514],\n",
       "       [0.31944084],\n",
       "       [0.31732532],\n",
       "       [0.34682706],\n",
       "       [0.50103843],\n",
       "       [0.6649924 ],\n",
       "       [0.58886546],\n",
       "       [0.5946922 ],\n",
       "       [0.25947493],\n",
       "       [0.6989844 ],\n",
       "       [0.28664488],\n",
       "       [0.6489586 ],\n",
       "       [0.4390859 ],\n",
       "       [0.42488033],\n",
       "       [0.42834905],\n",
       "       [0.43239993],\n",
       "       [0.6806985 ],\n",
       "       [0.53251773],\n",
       "       [0.42801526],\n",
       "       [0.4854939 ],\n",
       "       [0.59501547],\n",
       "       [0.26679447],\n",
       "       [0.63957006]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.470588 %\n",
      "Recall: 0.775510 %\n",
      "Fscore: 0.510753 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.634146 %\n",
      "Recall: 0.265306 %\n",
      "Fscore: 0.496183 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.6\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_filename = \"C:/Users/behl/Desktop/minor/train_data_sample_gray.p\"\n",
    "(train_labels, train_data, train_tensors) = pickle.load(open(train_filename, mode='rb'))\n",
    "\n",
    "valid_filename = \"C:/Users/behl/Desktop/minor/valid_data_sample_gray.p\"\n",
    "(valid_labels, valid_data, valid_tensors) = pickle.load(open(valid_filename, mode='rb'))\n",
    "\n",
    "test_filename = \"C:/Users/behl/Desktop/minor/test_data_sample_gray.p\"\n",
    "(test_labels, test_data, test_tensors) = pickle.load(open(test_filename, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 16)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 321,225\n",
      "Trainable params: 321,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers, initializers, optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=7,padding='same',activation='relu', \n",
    "                 input_shape=train_tensors.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=5,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=5,\n",
    "                 strides=2,\n",
    "                 padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def precision_threshold(threshold = 0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall\n",
    "\n",
    "def fbeta_score_threshold(beta = 1, threshold = 0.5):\n",
    "    def fbeta_score(y_true, y_pred):\n",
    "        threshold_value = threshold\n",
    "        beta_value = beta\n",
    "        p = precision_threshold(threshold_value)(y_true, y_pred)\n",
    "        r = recall_threshold(threshold_value)(y_true, y_pred)\n",
    "        bb = beta_value ** 2\n",
    "        fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "        return fbeta_score\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', \n",
    "              metrics=[precision_threshold(threshold = 0.5), \n",
    "                       recall_threshold(threshold = 0.5), \n",
    "                       fbeta_score_threshold(beta=0.5, threshold = 0.5),\n",
    "                      'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3400 samples, validate on 1100 samples\n",
      "Epoch 1/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6862 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5483\n",
      "Epoch 00001: val_loss improved from inf to 0.68914, saving model to C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 4s 1ms/sample - loss: 0.6861 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5485 - val_loss: 0.6891 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5345\n",
      "Epoch 2/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6847 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5485\n",
      "Epoch 00002: val_loss improved from 0.68914 to 0.68617, saving model to C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 793us/sample - loss: 0.6847 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5485 - val_loss: 0.6862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5345\n",
      "Epoch 3/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6826 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5478\n",
      "Epoch 00003: val_loss improved from 0.68617 to 0.68475, saving model to C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 2s 733us/sample - loss: 0.6826 - precision: 0.0000e+00 - recall: 0.0000e+00 - fbeta_score: 0.0000e+00 - acc: 0.5482 - val_loss: 0.6848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5345\n",
      "Epoch 4/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6813 - precision: 0.0991 - recall: 0.0112 - fbeta_score: 0.0367 - acc: 0.5522\n",
      "Epoch 00004: val_loss did not improve from 0.68475\n",
      "3400/3400 [==============================] - 3s 744us/sample - loss: 0.6812 - precision: 0.0981 - recall: 0.0111 - fbeta_score: 0.0364 - acc: 0.5529 - val_loss: 0.6880 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fbeta_score: 0.0000e+00 - val_acc: 0.5345\n",
      "Epoch 5/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6780 - precision: 0.3206 - recall: 0.0533 - fbeta_score: 0.1347 - acc: 0.5613\n",
      "Epoch 00005: val_loss improved from 0.68475 to 0.68010, saving model to C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 770us/sample - loss: 0.6780 - precision: 0.3333 - recall: 0.0591 - fbeta_score: 0.1429 - acc: 0.5615 - val_loss: 0.6801 - val_precision: 0.3000 - val_recall: 0.0235 - val_fbeta_score: 0.0878 - val_acc: 0.5400\n",
      "Epoch 6/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6747 - precision: 0.5318 - recall: 0.1761 - fbeta_score: 0.3237 - acc: 0.5805\n",
      "Epoch 00006: val_loss did not improve from 0.68010\n",
      "3400/3400 [==============================] - 3s 800us/sample - loss: 0.6746 - precision: 0.5268 - recall: 0.1744 - fbeta_score: 0.3207 - acc: 0.5812 - val_loss: 0.6930 - val_precision: 0.0571 - val_recall: 0.0039 - val_fbeta_score: 0.0152 - val_acc: 0.5355\n",
      "Epoch 7/20\n",
      "3360/3400 [============================>.] - ETA: 0s - loss: 0.6703 - precision: 0.6192 - recall: 0.2339 - fbeta_score: 0.4201 - acc: 0.5940\n",
      "Epoch 00007: val_loss did not improve from 0.68010\n",
      "3400/3400 [==============================] - 3s 769us/sample - loss: 0.6696 - precision: 0.6143 - recall: 0.2367 - fbeta_score: 0.4190 - acc: 0.5962 - val_loss: 0.6864 - val_precision: 0.5357 - val_recall: 0.0593 - val_fbeta_score: 0.1967 - val_acc: 0.5500\n",
      "Epoch 8/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6649 - precision: 0.5811 - recall: 0.3294 - fbeta_score: 0.4607 - acc: 0.6055\n",
      "Epoch 00008: val_loss improved from 0.68010 to 0.66816, saving model to C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5\n",
      "3400/3400 [==============================] - 3s 775us/sample - loss: 0.6641 - precision: 0.5832 - recall: 0.3451 - fbeta_score: 0.4670 - acc: 0.6079 - val_loss: 0.6682 - val_precision: 0.6314 - val_recall: 0.2758 - val_fbeta_score: 0.4849 - val_acc: 0.5936\n",
      "Epoch 9/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6616 - precision: 0.5984 - recall: 0.3912 - fbeta_score: 0.5076 - acc: 0.6025 ETA: 0s - loss: 0.6618 - precision: 0.5930 - recall: 0.3636 - fbeta\n",
      "Epoch 00009: val_loss did not improve from 0.66816\n",
      "3400/3400 [==============================] - 3s 811us/sample - loss: 0.6620 - precision: 0.5970 - recall: 0.3903 - fbeta_score: 0.5055 - acc: 0.6015 - val_loss: 0.6688 - val_precision: 0.6475 - val_recall: 0.2684 - val_fbeta_score: 0.4861 - val_acc: 0.5918\n",
      "Epoch 10/20\n",
      "3392/3400 [============================>.] - ETA: 0s - loss: 0.6589 - precision: 0.6082 - recall: 0.4267 - fbeta_score: 0.5332 - acc: 0.6085\n",
      "Epoch 00010: val_loss did not improve from 0.66816\n",
      "3400/3400 [==============================] - 3s 756us/sample - loss: 0.6587 - precision: 0.6119 - recall: 0.4290 - fbeta_score: 0.5367 - acc: 0.6091 - val_loss: 0.6824 - val_precision: 0.6464 - val_recall: 0.1834 - val_fbeta_score: 0.4057 - val_acc: 0.5727\n",
      "Epoch 11/20\n",
      "3328/3400 [============================>.] - ETA: 0s - loss: 0.6592 - precision: 0.5958 - recall: 0.4280 - fbeta_score: 0.5295 - acc: 0.6073\n",
      "Epoch 00011: val_loss did not improve from 0.66816\n",
      "3400/3400 [==============================] - 3s 782us/sample - loss: 0.6591 - precision: 0.5973 - recall: 0.4343 - fbeta_score: 0.5324 - acc: 0.6082 - val_loss: 0.6854 - val_precision: 0.6657 - val_recall: 0.1869 - val_fbeta_score: 0.4171 - val_acc: 0.5736\n",
      "Epoch 00011: early stopping\n",
      "training time: 0.54 minutes\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "log = CSVLogger('C:/Users/behl/Desktop/minor/log_bCNN_gray.csv')\n",
    "checkpointer = ModelCheckpoint(filepath='C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, valid_labels),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, log, earlystop], verbose=1)\n",
    "\n",
    "# Show total training time\n",
    "print(\"training time: %.2f minutes\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [[0.40149194]\n",
      " [0.35671026]\n",
      " [0.5295818 ]\n",
      " [0.34850624]\n",
      " [0.39328128]\n",
      " [0.37793422]\n",
      " [0.50623745]\n",
      " [0.3037331 ]\n",
      " [0.34244263]\n",
      " [0.3514979 ]\n",
      " [0.3343041 ]\n",
      " [0.41950437]\n",
      " [0.5871829 ]\n",
      " [0.52777535]\n",
      " [0.50695014]\n",
      " [0.26181662]\n",
      " [0.60289854]\n",
      " [0.2928931 ]\n",
      " [0.5821857 ]\n",
      " [0.42113817]\n",
      " [0.3810205 ]\n",
      " [0.4062845 ]\n",
      " [0.39560556]\n",
      " [0.58394516]\n",
      " [0.4489488 ]\n",
      " [0.4220333 ]\n",
      " [0.42086747]\n",
      " [0.51065487]\n",
      " [0.3628356 ]\n",
      " [0.51080847]\n",
      " [0.29644528]\n",
      " [0.28684705]\n",
      " [0.37411666]\n",
      " [0.44644073]\n",
      " [0.48257244]\n",
      " [0.562293  ]\n",
      " [0.38482314]\n",
      " [0.3003142 ]\n",
      " [0.29670328]\n",
      " [0.32793838]\n",
      " [0.5231838 ]\n",
      " [0.40151122]\n",
      " [0.32805848]\n",
      " [0.34543204]\n",
      " [0.3906322 ]\n",
      " [0.53488   ]\n",
      " [0.5029401 ]\n",
      " [0.577196  ]\n",
      " [0.35210353]\n",
      " [0.36534774]\n",
      " [0.3426104 ]\n",
      " [0.3797388 ]\n",
      " [0.38672924]\n",
      " [0.6194257 ]\n",
      " [0.48896292]\n",
      " [0.41161206]\n",
      " [0.4479072 ]\n",
      " [0.4495389 ]\n",
      " [0.37746477]\n",
      " [0.3737647 ]\n",
      " [0.49621266]\n",
      " [0.53151995]\n",
      " [0.42121005]\n",
      " [0.36705267]\n",
      " [0.38133258]\n",
      " [0.5202369 ]\n",
      " [0.54733145]\n",
      " [0.44987062]\n",
      " [0.27751392]\n",
      " [0.2847425 ]\n",
      " [0.38998002]\n",
      " [0.3890326 ]\n",
      " [0.28179365]\n",
      " [0.35496163]\n",
      " [0.5300161 ]\n",
      " [0.5706452 ]\n",
      " [0.43966362]\n",
      " [0.38855147]\n",
      " [0.42526972]\n",
      " [0.37467706]\n",
      " [0.3559674 ]\n",
      " [0.47346815]\n",
      " [0.49194652]\n",
      " [0.39670867]\n",
      " [0.4956884 ]\n",
      " [0.28061616]\n",
      " [0.46420905]\n",
      " [0.40906066]\n",
      " [0.43400663]\n",
      " [0.42055458]\n",
      " [0.5527223 ]\n",
      " [0.5518044 ]\n",
      " [0.4686434 ]\n",
      " [0.42603946]\n",
      " [0.36599898]\n",
      " [0.5540524 ]\n",
      " [0.37815958]\n",
      " [0.4583148 ]\n",
      " [0.4490872 ]\n",
      " [0.40235913]\n",
      " [0.44706744]\n",
      " [0.367494  ]\n",
      " [0.3793126 ]\n",
      " [0.405009  ]\n",
      " [0.43053526]\n",
      " [0.51139   ]\n",
      " [0.4525114 ]\n",
      " [0.35417408]\n",
      " [0.3617128 ]\n",
      " [0.40183926]\n",
      " [0.3432691 ]\n",
      " [0.41831532]\n",
      " [0.5444206 ]\n",
      " [0.41049954]\n",
      " [0.47142234]\n",
      " [0.41913614]\n",
      " [0.31771654]\n",
      " [0.4660562 ]\n",
      " [0.42802972]\n",
      " [0.34543523]\n",
      " [0.4833194 ]\n",
      " [0.41552892]\n",
      " [0.4502551 ]\n",
      " [0.40023482]\n",
      " [0.26461807]\n",
      " [0.451783  ]\n",
      " [0.4364483 ]\n",
      " [0.46824723]\n",
      " [0.4225829 ]\n",
      " [0.37961513]\n",
      " [0.32019058]\n",
      " [0.4146096 ]\n",
      " [0.5160528 ]\n",
      " [0.6221311 ]\n",
      " [0.3041311 ]\n",
      " [0.38147226]\n",
      " [0.47595865]\n",
      " [0.43606967]\n",
      " [0.43128082]\n",
      " [0.41974884]\n",
      " [0.42833745]\n",
      " [0.4282109 ]\n",
      " [0.3017393 ]\n",
      " [0.5320865 ]\n",
      " [0.31018794]\n",
      " [0.3402519 ]\n",
      " [0.5259473 ]\n",
      " [0.40495893]\n",
      " [0.4495537 ]\n",
      " [0.35831058]\n",
      " [0.45617983]\n",
      " [0.48830655]\n",
      " [0.5055216 ]\n",
      " [0.3881859 ]\n",
      " [0.4318536 ]\n",
      " [0.258657  ]\n",
      " [0.48198467]\n",
      " [0.3176067 ]\n",
      " [0.33621037]\n",
      " [0.6495246 ]\n",
      " [0.26173228]\n",
      " [0.287863  ]\n",
      " [0.26361668]\n",
      " [0.49623126]\n",
      " [0.42732322]\n",
      " [0.38648793]\n",
      " [0.3748412 ]\n",
      " [0.46636462]\n",
      " [0.39201358]\n",
      " [0.3339214 ]\n",
      " [0.33575156]\n",
      " [0.50141376]\n",
      " [0.3798495 ]\n",
      " [0.38133588]\n",
      " [0.5043457 ]\n",
      " [0.4239905 ]\n",
      " [0.38983348]\n",
      " [0.424352  ]\n",
      " [0.51106334]\n",
      " [0.3862403 ]\n",
      " [0.3528868 ]\n",
      " [0.42722148]\n",
      " [0.33050367]\n",
      " [0.28216776]\n",
      " [0.2847842 ]\n",
      " [0.58498365]\n",
      " [0.47718543]\n",
      " [0.3929334 ]\n",
      " [0.32173675]\n",
      " [0.5623668 ]\n",
      " [0.3205895 ]\n",
      " [0.35920224]\n",
      " [0.47856298]\n",
      " [0.48898134]\n",
      " [0.3618973 ]\n",
      " [0.2760948 ]\n",
      " [0.5467435 ]\n",
      " [0.55832076]\n",
      " [0.35993314]\n",
      " [0.4177419 ]\n",
      " [0.32988298]\n",
      " [0.36512002]\n",
      " [0.46564525]\n",
      " [0.3837771 ]\n",
      " [0.39804897]\n",
      " [0.61798024]\n",
      " [0.30145466]\n",
      " [0.37547585]\n",
      " [0.40283248]\n",
      " [0.4687002 ]\n",
      " [0.403692  ]\n",
      " [0.3992116 ]\n",
      " [0.57142735]\n",
      " [0.60729533]\n",
      " [0.5567744 ]\n",
      " [0.3332796 ]\n",
      " [0.3132977 ]\n",
      " [0.3115077 ]\n",
      " [0.47760957]\n",
      " [0.35262096]\n",
      " [0.36065218]\n",
      " [0.36092895]\n",
      " [0.44254142]\n",
      " [0.42769808]\n",
      " [0.5199613 ]\n",
      " [0.53303677]\n",
      " [0.4631644 ]\n",
      " [0.41038874]\n",
      " [0.3956936 ]\n",
      " [0.555621  ]\n",
      " [0.4983155 ]\n",
      " [0.63564533]\n",
      " [0.44651818]\n",
      " [0.5468055 ]\n",
      " [0.3560437 ]\n",
      " [0.4428422 ]\n",
      " [0.24274555]\n",
      " [0.5936585 ]\n",
      " [0.39332592]\n",
      " [0.5063301 ]\n",
      " [0.3216499 ]\n",
      " [0.2851944 ]\n",
      " [0.53445387]\n",
      " [0.4720003 ]\n",
      " [0.40813363]\n",
      " [0.24115404]\n",
      " [0.3128618 ]\n",
      " [0.3918628 ]\n",
      " [0.52193385]\n",
      " [0.42061478]\n",
      " [0.57399225]\n",
      " [0.3086269 ]\n",
      " [0.3791457 ]\n",
      " [0.41088232]\n",
      " [0.42335045]\n",
      " [0.44712153]\n",
      " [0.32625166]\n",
      " [0.25901687]\n",
      " [0.3857788 ]\n",
      " [0.44011405]\n",
      " [0.44966546]\n",
      " [0.37110847]\n",
      " [0.39851856]\n",
      " [0.52717346]\n",
      " [0.6386931 ]\n",
      " [0.42772236]\n",
      " [0.27014667]\n",
      " [0.43315288]\n",
      " [0.37154755]\n",
      " [0.33937925]\n",
      " [0.4923076 ]\n",
      " [0.43236366]\n",
      " [0.4669968 ]\n",
      " [0.35526353]\n",
      " [0.2782808 ]\n",
      " [0.50218076]\n",
      " [0.4915191 ]\n",
      " [0.44313607]\n",
      " [0.5253352 ]\n",
      " [0.42765865]\n",
      " [0.39501983]\n",
      " [0.44621074]\n",
      " [0.35318625]\n",
      " [0.66000915]\n",
      " [0.5412149 ]\n",
      " [0.42686504]\n",
      " [0.5189878 ]\n",
      " [0.43712983]\n",
      " [0.3544883 ]\n",
      " [0.36593032]\n",
      " [0.6228483 ]\n",
      " [0.42517814]\n",
      " [0.39439014]\n",
      " [0.27204514]\n",
      " [0.401972  ]\n",
      " [0.40996847]\n",
      " [0.50929976]\n",
      " [0.3567347 ]\n",
      " [0.34266937]\n",
      " [0.52578306]\n",
      " [0.44086456]\n",
      " [0.46748787]\n",
      " [0.58141977]\n",
      " [0.3590989 ]\n",
      " [0.26815766]\n",
      " [0.5049499 ]\n",
      " [0.34860128]\n",
      " [0.3253914 ]\n",
      " [0.4457116 ]\n",
      " [0.41795567]\n",
      " [0.30464268]\n",
      " [0.4736819 ]\n",
      " [0.3830052 ]\n",
      " [0.33857   ]\n",
      " [0.28891587]\n",
      " [0.26725483]\n",
      " [0.51732224]\n",
      " [0.32284364]\n",
      " [0.38998476]\n",
      " [0.3637676 ]\n",
      " [0.5602595 ]\n",
      " [0.56207305]\n",
      " [0.28233397]\n",
      " [0.3875003 ]\n",
      " [0.33867696]\n",
      " [0.25568208]\n",
      " [0.5013025 ]\n",
      " [0.33952773]\n",
      " [0.33310938]\n",
      " [0.27808604]\n",
      " [0.30896595]\n",
      " [0.3699292 ]\n",
      " [0.34575123]\n",
      " [0.33303016]\n",
      " [0.3984055 ]\n",
      " [0.53355324]\n",
      " [0.44090074]\n",
      " [0.5768135 ]\n",
      " [0.59335166]\n",
      " [0.3957474 ]\n",
      " [0.40665048]\n",
      " [0.5463023 ]\n",
      " [0.43554398]\n",
      " [0.3212844 ]\n",
      " [0.3927756 ]\n",
      " [0.26904607]\n",
      " [0.4260087 ]\n",
      " [0.52397466]\n",
      " [0.38271412]\n",
      " [0.5929663 ]\n",
      " [0.39054167]\n",
      " [0.34119755]\n",
      " [0.35495603]\n",
      " [0.40362749]\n",
      " [0.2687418 ]\n",
      " [0.41156596]\n",
      " [0.36906326]\n",
      " [0.36356765]\n",
      " [0.52564466]\n",
      " [0.57432824]\n",
      " [0.48630053]\n",
      " [0.35957897]\n",
      " [0.60137624]\n",
      " [0.35534292]\n",
      " [0.29359198]\n",
      " [0.3941815 ]\n",
      " [0.35301292]\n",
      " [0.44923717]\n",
      " [0.31279507]\n",
      " [0.33344716]\n",
      " [0.37690744]\n",
      " [0.2760703 ]\n",
      " [0.37247372]\n",
      " [0.36008912]\n",
      " [0.44128382]\n",
      " [0.53804475]\n",
      " [0.48401833]\n",
      " [0.3783518 ]\n",
      " [0.4812753 ]\n",
      " [0.56680596]\n",
      " [0.43824294]\n",
      " [0.5085817 ]\n",
      " [0.3966552 ]\n",
      " [0.4876085 ]\n",
      " [0.5154281 ]\n",
      " [0.42203414]\n",
      " [0.5020902 ]\n",
      " [0.2880668 ]\n",
      " [0.45656675]\n",
      " [0.4663559 ]\n",
      " [0.40239605]\n",
      " [0.3670168 ]\n",
      " [0.43199062]\n",
      " [0.5059322 ]\n",
      " [0.3415052 ]\n",
      " [0.33104712]\n",
      " [0.37458584]\n",
      " [0.36594072]\n",
      " [0.40923548]\n",
      " [0.41689524]\n",
      " [0.5807837 ]\n",
      " [0.38673165]\n",
      " [0.3734668 ]\n",
      " [0.38792104]\n",
      " [0.39937466]\n",
      " [0.41254738]\n",
      " [0.58007383]\n",
      " [0.32161903]\n",
      " [0.5233481 ]\n",
      " [0.47809613]\n",
      " [0.53659624]\n",
      " [0.4517762 ]\n",
      " [0.26333818]\n",
      " [0.24654037]\n",
      " [0.37655884]\n",
      " [0.5500128 ]\n",
      " [0.3469674 ]\n",
      " [0.458664  ]\n",
      " [0.47769806]\n",
      " [0.41161245]\n",
      " [0.36695105]\n",
      " [0.31306085]\n",
      " [0.5417128 ]\n",
      " [0.22592488]\n",
      " [0.38262248]\n",
      " [0.33459663]\n",
      " [0.27732268]\n",
      " [0.5479153 ]\n",
      " [0.46583614]\n",
      " [0.4596536 ]\n",
      " [0.37046048]\n",
      " [0.5174652 ]\n",
      " [0.42896587]\n",
      " [0.45294172]\n",
      " [0.4869349 ]\n",
      " [0.37277842]\n",
      " [0.52605075]\n",
      " [0.3414786 ]\n",
      " [0.4606939 ]\n",
      " [0.37810978]\n",
      " [0.46458328]\n",
      " [0.47988716]\n",
      " [0.56151015]\n",
      " [0.50084966]\n",
      " [0.44841814]\n",
      " [0.3609328 ]\n",
      " [0.41128218]\n",
      " [0.28336024]\n",
      " [0.43557054]\n",
      " [0.41998386]\n",
      " [0.47430244]\n",
      " [0.33813012]\n",
      " [0.46745163]\n",
      " [0.535352  ]\n",
      " [0.48316753]\n",
      " [0.45667708]\n",
      " [0.5039952 ]\n",
      " [0.6008029 ]\n",
      " [0.40997887]\n",
      " [0.33337986]\n",
      " [0.42948726]\n",
      " [0.38375854]\n",
      " [0.3439855 ]\n",
      " [0.3896324 ]\n",
      " [0.32139206]\n",
      " [0.32661787]\n",
      " [0.40635347]\n",
      " [0.49956778]\n",
      " [0.3256215 ]\n",
      " [0.4331632 ]\n",
      " [0.2563749 ]\n",
      " [0.37593862]\n",
      " [0.33947375]\n",
      " [0.4808567 ]\n",
      " [0.3349625 ]\n",
      " [0.444081  ]\n",
      " [0.61325246]\n",
      " [0.37701565]\n",
      " [0.3277008 ]\n",
      " [0.45636624]\n",
      " [0.36411127]\n",
      " [0.26437074]\n",
      " [0.47102973]\n",
      " [0.33308107]\n",
      " [0.38323146]\n",
      " [0.42674997]\n",
      " [0.27748054]\n",
      " [0.44305936]\n",
      " [0.38357872]\n",
      " [0.4309977 ]\n",
      " [0.39778465]\n",
      " [0.5621887 ]\n",
      " [0.29291192]\n",
      " [0.4783875 ]\n",
      " [0.38961232]\n",
      " [0.5060606 ]\n",
      " [0.45819557]\n",
      " [0.36139518]]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('C:/Users/behl/Desktop/minor/bCNN_gray.best.from_scratch.hdf5')\n",
    "prediction = model.predict(test_tensors)\n",
    "print('prediction',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.594059 %\n",
      "Recall: 0.306122 %\n",
      "Fscore: 0.500000 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64457834"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(binary_accuracy(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40149194],\n",
       "       [0.35671026],\n",
       "       [0.5295818 ],\n",
       "       [0.34850624],\n",
       "       [0.39328128],\n",
       "       [0.37793422],\n",
       "       [0.50623745],\n",
       "       [0.3037331 ],\n",
       "       [0.34244263],\n",
       "       [0.3514979 ],\n",
       "       [0.3343041 ],\n",
       "       [0.41950437],\n",
       "       [0.5871829 ],\n",
       "       [0.52777535],\n",
       "       [0.50695014],\n",
       "       [0.26181662],\n",
       "       [0.60289854],\n",
       "       [0.2928931 ],\n",
       "       [0.5821857 ],\n",
       "       [0.42113817],\n",
       "       [0.3810205 ],\n",
       "       [0.4062845 ],\n",
       "       [0.39560556],\n",
       "       [0.58394516],\n",
       "       [0.4489488 ],\n",
       "       [0.4220333 ],\n",
       "       [0.42086747],\n",
       "       [0.51065487],\n",
       "       [0.3628356 ],\n",
       "       [0.51080847]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.509294 %\n",
      "Recall: 0.698980 %\n",
      "Fscore: 0.538522 %\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "beta = 0.5\n",
    "\n",
    "pre = K.eval(precision_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "rec = K.eval(recall_threshold(threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "fsc = K.eval(fbeta_score_threshold(beta = beta, threshold = threshold)(K.variable(value=test_labels),\n",
    "                                   K.variable(value=prediction)))\n",
    "\n",
    "print (\"Precision: %f %%\\nRecall: %f %%\\nFscore: %f %%\"% (pre, rec, fsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
